{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#estimators\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, ExtraTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from dataset_loader import load_dataset, preprocessing\n",
        "from Boosting_models import MulticlassClassificationOvR, LogitBoost, MEBoost, AdaBoost, RUSBoost, GradientBoostingClassifier\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
        "from scipy.stats import hmean\n",
        "\n",
        "\n",
        "\n",
        "def gmean_score(y_true, y_pred):\n",
        "    return hmean([precision_score(y_true, y_pred, average='weighted'), recall_score(y_true, y_pred, average='weighted')])\n",
        "\n",
        "def weighted_accuracy(y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred, normalize=False)\n",
        "    return acc / len(y_true)\n",
        "\n",
        "\n",
        "def find_best_base_estimator(base_estimators, X_train, y_train):\n",
        "    best_params = {}\n",
        "\n",
        "    for name, estimator in base_estimators.items():\n",
        "        param_grid = {}\n",
        "\n",
        "        if name in ['DecisionTreeClassifier', 'ExtraTreeClassifier', 'DecisionTreeRegressor']:\n",
        "            param_grid = {\n",
        "                'max_depth': [3, 5, 10],\n",
        "                'min_samples_split': [2, 5, 10],\n",
        "                'min_samples_leaf': [1, 2, 4],\n",
        "                'max_features': ['auto', 'sqrt', 'log2']\n",
        "            }\n",
        "        elif name == 'LogisticRegression':\n",
        "            param_grid = {\n",
        "                'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                'penalty': ['l1', 'l2']\n",
        "            }\n",
        "        elif name == 'SVC':\n",
        "            param_grid = {\n",
        "                'C': [0.1, 1, 10, 100],\n",
        "                'gamma': ['scale', 'auto'],\n",
        "                'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "            }\n",
        "        else:\n",
        "            continue\n",
        "        skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
        "        grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=skf, scoring='accuracy')\n",
        "        grid_search.fit(X_train, y_train)\n",
        "        best_params[name] = grid_search.best_params_\n",
        "\n",
        "\n",
        "\n",
        "        # Output of model quality metrics\n",
        "        cv_results = grid_search.cv_results_\n",
        "        mean_test_score = cv_results['mean_test_score']\n",
        "        params = cv_results['params']\n",
        "\n",
        "        # print(\"Metrics for\", name)\n",
        "        with open('results_gs.txt', 'a') as f:\n",
        "            f.write(f\"Metrics for {name}\\n\")\n",
        "\n",
        "        for mean_score, param in zip(mean_test_score, params):\n",
        "            # print(\"Mean accuracy:\", mean_score, \"Params:\", param)\n",
        "            with open('results_gs.txt', 'a') as f:\n",
        "                f.write(f\"Mean accuracy: {mean_score}, Params:, {param}\\n\")\n",
        "\n",
        "    return best_params\n",
        "\n",
        "def main():\n",
        "    dataset_names = ['Wine', 'Hayes_Roth', 'Contraceptive_Method_Choice',\n",
        "                    'Pen-Based_Recognition_of_Handwritten_Digits',\n",
        "                    'Vertebral_Column', 'Differentiated_Thyroid_Cancer_Recurrence',\n",
        "                    'Dermatology', 'Balance_Scale', 'Glass_Identification',\n",
        "                    'Heart_Disease', 'Car_Evaluation', 'Thyroid_Disease', 'Yeast',\n",
        "                     'Page_Blocks_Classification', 'Statlog_Shuttle', 'Covertype'\n",
        "    ]\n",
        "\n",
        "    base_estimators = {\n",
        "        'DecisionTreeClassifier': DecisionTreeClassifier(),\n",
        "        'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
        "        'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
        "        'LogisticRegression': LogisticRegression(),\n",
        "        'SVC': SVC()\n",
        "    }\n",
        "\n",
        "    boosting_models = {\n",
        "        'AdaBoost': AdaBoost(),\n",
        "        'RUSBoost': RUSBoost(),\n",
        "        # 'XGBClassifier': XGBClassifier(),\n",
        "        # 'CatBoostClassifier': CatBoostClassifier(),\n",
        "        # 'SMOTE': SMOTE(),\n",
        "        # 'LogitBoost': LogitBoost(),\n",
        "        # 'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "        # 'MEBoost': MEBoost()\n",
        "    }\n",
        "\n",
        "    for dataset_name in dataset_names:\n",
        "        with open('metrics_on_ds.txt', 'a') as f:\n",
        "            f.write(f\"Metrics for {dataset_name}\\n\")\n",
        "        X, y = load_dataset(dataset_name)\n",
        "        X_train, X_test, y_train, y_test = preprocessing(X, y, scaler=StandardScaler(), test_size=0.3, random_state=42)\n",
        "        best_params = find_best_base_estimator(base_estimators, X_train, y_train)\n",
        "\n",
        "        # Training boosting models on base models with the best parameters\n",
        "        for base_model, params in best_params.items():\n",
        "            base_estimator = eval(base_model)(**params)\n",
        "            for boosting_name, boosting_model in boosting_models.items():\n",
        "                model = eval(boosting_name)(base_estimator=base_estimator, n_estimators=50)\n",
        "                boosting_model = MulticlassClassificationOvR(model)\n",
        "                boosting_model.fit(X_train, y_train)\n",
        "\n",
        "                print(\"Boosting model with base estimator\", base_model, \"trained.\")\n",
        "                y_pred = boosting_model.predict(X_test)\n",
        "                print('gmean_score:', gmean_score(y_test, y_pred))\n",
        "                print('weighted_accuracy:', weighted_accuracy(y_test, y_pred))\n",
        "                with open('metrics_on_ds.txt', 'a') as f:\n",
        "                    f.write(f\"Boosting model with base estimator: {base_model}\")\n",
        "                    f.write(f\"gmean_score: {gmean_score(y_test, y_pred)}\\n\")\n",
        "                    f.write(f\"weighted_accuracy: {weighted_accuracy(y_test, y_pred)}\\n\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "MqY9JaxYMcLt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3k0ctjgu4Ww9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ymXclNq44Wtw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
